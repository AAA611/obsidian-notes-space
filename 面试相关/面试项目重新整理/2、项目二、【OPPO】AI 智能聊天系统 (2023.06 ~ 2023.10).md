
`Vue3` `Pinia` `Vite` `TypeScript` `Docker` `Nginx` `Jenkins`
- **项目描述**
	 一个用于公司内部人员的一款 AI 聊天软件。包括 PC 端网站、PC 浏览器插件、公共库。主要功能有 AI 聊天、定制化 AI 聊天指令等
- **人员规模** 
	 研发 3，前端 1
- **负责内容**
	1. 项目从 0 到 1 的搭建、功能开发、迭代、维护
	3. 基于 Docker、 Nginx、Jenkins 实现简单的项目自动化部署工作流
	4. 聊天功能的浏览器插件开发、公共逻辑抽离复用
- **难点与亮点**：
	1. 使用 IndexDB 代替 LocalStorage 的优化聊天内容的存储
	2. 实现聊天功能插件系统，便于聊天功能扩展
	3. 封装聊天功能核心逻辑与组件，在多个项目中实现复用
	4. 使用 ShadowDOM 实现浏览器插件的样式隔离


### 为什么使用 indexDB 代替 localStorage 来优化？

A1：容量问题：出于一些原因，用户的聊天记录存储在客户端，考虑到用户的聊天记录可能内容会非常多，所以 locaStorage 的容量较小的问题满足不了当下的需求场景，经过调研所以采用了容量更大的客户端存储方式 indexDB
A2：聊天记录的查询场景：聊天记录的存储方式是根据不同的聊天上下文以不同的 key 存储在一个大的对象中，每个聊天上下文中又包含了许多的聊天内容信息等。在切换聊天上下文时需要把整个对象从 localStorage 取出来然后找到要切换的聊天上下文中。这样需要使用 JSON. parse 然后再内存中操作整个大的对象然后查找。indexDB 是一个客户端的 NoSQL 数据库实现，天然具有查询数据的功能与优势，并且 indexDB 数据库可以建立索引加速查询过程。
A3：聊天记录的保存：聊天记录的保存是再用户的一次对话结束后进行的，相对来说还是比较频繁。使用 localStorage 进行保存时，需要先从 localStorage 查出来整个，然后更新这个对象，然后再存进去，这个过程中会使用到 JOSN. parse、JSON. stringfy 这两个方法，在数据量比较大的时候，JSON. parse、JSON. stringfy 是比较耗性能的。另外由于 localStorage 的操作是同步进行的，也就是说会阻塞主线程，由于 JavaScript 是单线程的，所以如果一旦在存储聊天记录的过程中消耗了比较长的时间的话，会造成页面的卡顿。而 indexDB 的操作都是异步进行的，这不会阻塞 JavaScript 主线程的执行，并且不需要把整个聊天记录对象都查出来在内存进行操作。

所以鉴于以上的集中情况和考虑，使用 indexDB 来在客户端存储聊天记录内容是比较合适的

### 聊天功能是怎么实现的？

A1：基于 EventSource 实现服务端的流数据推送来实现流式的这个聊天效果
A2：客户端的聊天气泡框使用 markdown 来渲染接收到的 markdown 文本流，出于便于扩展的目的，聊天气泡框默认渲染 markdown 文本流，但还可以很方便地渲染其他任意组件来满足不同的场景需要（例如有一个场景不是流式的聊天，而是服务端返回几个链接，客户端需要把链接渲染成一个个精美的卡片，这就需要在气泡框中渲染自定义组件了，另外对于这种聊天记录的保存上，只需要保存这个自定义组件渲染时所需要的数据和自定义组件类型，在渲染聊天记录时根据类型找到使用哪个自定义组件，然后根据数据还原当时的聊天记录）
A3：

### 为什么不选择使用 websocket 来做？

A1：第一点，我们在选择使用某个技术来实现某个业务场景/功能的时候，要考虑到在满足业务需求的同时降低一些成本、应用的复杂度等情况。websocket 是一个全双工的通信方式，双方都可以主动向对方发送消息，那聊天的场景仅限于客户端发起某个聊天，服务端收到这个客户端发来的内容之后做一下流式响应。在这个基本的业务场景下，客户端与服务端基本上式疑问一答，不需要服务端主动向客户都安推送消息。那么这个时候使用底层是基于 HTTP 1.1 的 keep-alive 的 EventSource 是非常贴合场景的。
A2：使用 websocket 让服务端保持一个 ws 链接是不够合理的，也过多消耗了服务端的资源




